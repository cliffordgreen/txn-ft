{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transaction Categorization Fine-Tuning\n",
    "\n",
    "This notebook demonstrates how to fine-tune a language model to categorize financial transactions using a multiple-choice approach.\n",
    "\n",
    "## Overview\n",
    "\n",
    "Financial transaction categorization is a common task in personal finance apps. This notebook improves upon traditional approaches by:\n",
    "\n",
    "1. Presenting the model with 5 potential categories (including the correct one)\n",
    "2. Using a structured format for responses with reasoning and answers\n",
    "3. Providing a clear system prompt with instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's install the required dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install torch datasets transformers trl accelerate sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import os\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM, \n",
    "    AutoTokenizer, \n",
    "    TrainingArguments\n",
    ")\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define System Prompt and Transaction Categories\n",
    "\n",
    "Let's define the system prompt and the list of valid transaction categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define system prompt\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a financial assistant that categorizes transactions.\n",
    "For each transaction, you will be given the description, amount, and five possible categories.\n",
    "Choose the most appropriate category from the given options.\n",
    "\n",
    "Respond in the following format:\n",
    "<reasoning>\n",
    "Think step by step about the transaction details and determine the appropriate category from the provided options.\n",
    "</reasoning>\n",
    "<answer>\n",
    "[SELECTED CATEGORY]\n",
    "</answer>\n",
    "\"\"\"\n",
    "\n",
    "# Define all valid categories\n",
    "ALL_CATEGORIES = [\n",
    "    \"Food & Dining\", \"Shopping\", \"Transportation\", \"Entertainment\", \n",
    "    \"Health & Medical\", \"Groceries\", \"Insurance\", \"Bills & Utilities\",\n",
    "    \"Auto & Transport\", \"Travel\", \"Income\", \"Transfer\", \"Education\",\n",
    "    \"Personal Care\", \"Gifts & Donations\", \"Fees & Charges\"\n",
    "]\n",
    "\n",
    "print(f\"Total categories: {len(ALL_CATEGORIES)}\")\n",
    "print(\"Sample categories: \", \", \".join(ALL_CATEGORIES[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset\n",
    "\n",
    "Next, we'll prepare our dataset of transactions and format it for fine-tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to get random category options\n",
    "def get_category_options(correct_category):\n",
    "    # Remove the correct category from options\n",
    "    other_categories = [cat for cat in ALL_CATEGORIES if cat != correct_category]\n",
    "    # Select 4 random categories\n",
    "    random_categories = random.sample(other_categories, 4)\n",
    "    # Add back the correct category and shuffle\n",
    "    all_options = random_categories + [correct_category]\n",
    "    random.shuffle(all_options)\n",
    "    return all_options\n",
    "\n",
    "# Sample transaction data\n",
    "def get_transaction_dataset() -> Dataset:\n",
    "    transactions = [\n",
    "        {\"description\": \"STARBUCKS COFFEE #123\", \"amount\": 5.75, \"category\": \"Food & Dining\"},\n",
    "        {\"description\": \"AMAZON.COM AMZN.COM/BI\", \"amount\": 29.99, \"category\": \"Shopping\"},\n",
    "        {\"description\": \"UBER TRIP 12345\", \"amount\": 18.50, \"category\": \"Transportation\"},\n",
    "        {\"description\": \"NETFLIX.COM\", \"amount\": 13.99, \"category\": \"Entertainment\"},\n",
    "        {\"description\": \"CVS PHARMACY #1234\", \"amount\": 32.47, \"category\": \"Health & Medical\"},\n",
    "        {\"description\": \"WALMART GROCERY\", \"amount\": 87.65, \"category\": \"Groceries\"},\n",
    "        {\"description\": \"GEICO AUTO INSURANCE\", \"amount\": 112.00, \"category\": \"Insurance\"},\n",
    "        {\"description\": \"AT&T WIRELESS\", \"amount\": 85.99, \"category\": \"Bills & Utilities\"},\n",
    "        {\"description\": \"SHELL OIL 12345\", \"amount\": 45.23, \"category\": \"Auto & Transport\"},\n",
    "        {\"description\": \"MARRIOTT HOTELS\", \"amount\": 189.99, \"category\": \"Travel\"},\n",
    "    ]\n",
    "    \n",
    "    # Add more varied examples\n",
    "    more_transactions = [\n",
    "        {\"description\": \"PAYPAL *TRANSFER\", \"amount\": 100.00, \"category\": \"Transfer\"},\n",
    "        {\"description\": \"DEPOSIT - THANK YOU\", \"amount\": 1250.00, \"category\": \"Income\"},\n",
    "        {\"description\": \"UNIVERSITY BOOKSTORE\", \"amount\": 75.50, \"category\": \"Education\"},\n",
    "        {\"description\": \"SUPERCUTS\", \"amount\": 25.00, \"category\": \"Personal Care\"},\n",
    "        {\"description\": \"AMERICAN RED CROSS\", \"amount\": 50.00, \"category\": \"Gifts & Donations\"},\n",
    "        {\"description\": \"LATE PAYMENT FEE\", \"amount\": 35.00, \"category\": \"Fees & Charges\"},\n",
    "    ]\n",
    "    \n",
    "    transactions.extend(more_transactions)\n",
    "    \n",
    "    # Create a Dataset object\n",
    "    data = Dataset.from_dict({\n",
    "        \"description\": [t[\"description\"] for t in transactions],\n",
    "        \"amount\": [t[\"amount\"] for t in transactions],\n",
    "        \"category\": [t[\"category\"] for t in transactions]\n",
    "    })\n",
    "    \n",
    "    # Map function that correctly handles category options\n",
    "    def create_example(example):\n",
    "        # Generate options just once per example\n",
    "        options = get_category_options(example['category'])\n",
    "        \n",
    "        # Format the options as a bulleted list\n",
    "        options_text = \"- \" + \"\\n- \".join(options)\n",
    "        \n",
    "        # Create the input prompt\n",
    "        input_text = f\"{SYSTEM_PROMPT}\\n\\nUser: Categorize this transaction: Description: {example['description']}, Amount: ${example['amount']}\\n\\nPossible categories:\\n{options_text}\\n\\nAssistant:\"\n",
    "        \n",
    "        # Create the expected response\n",
    "        response_text = f\" <reasoning>\\nThis transaction is from {example['description']} for ${example['amount']}. Based on the merchant name and amount, this is clearly a {example['category']} transaction.\\n</reasoning>\\n<answer>\\n{example['category']}\\n</answer>\"\n",
    "        \n",
    "        return {\n",
    "            \"input_text\": input_text,\n",
    "            \"response_text\": response_text,\n",
    "            \"text\": input_text + response_text,\n",
    "            \"category_options\": options,\n",
    "            \"correct_category\": example['category']\n",
    "        }\n",
    "    \n",
    "    # Apply the mapping function\n",
    "    data = data.map(create_example)\n",
    "    return data\n",
    "\n",
    "# Create the dataset\n",
    "dataset = get_transaction_dataset()\n",
    "print(f\"Dataset size: {len(dataset)} examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine a sample from our dataset to confirm it's formatted correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a sample example\n",
    "sample_idx = 0  # Choose any index from 0 to len(dataset)-1\n",
    "sample = dataset[sample_idx]\n",
    "\n",
    "print(f\"Transaction: {sample['description']}, Amount: ${sample['amount']}\")\n",
    "print(f\"Correct category: {sample['correct_category']}\")\n",
    "print(\"Provided category options:\")\n",
    "for option in sample['category_options']:\n",
    "    print(f\"- {option}\")\n",
    "    \n",
    "print(\"\\nPrompt:\")\n",
    "print(sample['input_text'])\n",
    "\n",
    "print(\"\\nExpected completion:\")\n",
    "print(sample['response_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune a Model\n",
    "\n",
    "Now we'll select a model to fine-tune. We'll use a lightweight model for demonstration purposes, but for better results, you might want to use a larger model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the model you want to fine-tune\n",
    "# For smaller compute requirements, use a smaller model like \"microsoft/phi-2\"\n",
    "# For better results, use a larger model like \"meta-llama/Llama-2-7b-hf\"\n",
    "model_name = \"microsoft/phi-2\"  # Replace with your preferred model\n",
    "\n",
    "# Create a directory for saving model outputs\n",
    "output_dir = \"categorization-model\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    # Load tokenizer\n",
    "    print(f\"Loading tokenizer for {model_name}...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    # Load model\n",
    "    print(f\"Loading model {model_name}...\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        device_map=\"auto\",  # Automatically distribute across available GPUs\n",
    "        trust_remote_code=True,\n",
    "    )\n",
    "    \n",
    "    print(f\"Model loaded successfully with {sum(p.numel() for p in model.parameters())/1e6:.1f}M parameters\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    print(\"\\nNote: If you're running this notebook in an environment without GPU,\")\n",
    "    print(\"you may want to modify the device_map parameter or use a smaller model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    save_steps=10,\n",
    "    logging_steps=10,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=5,\n",
    "    optim=\"adamw_torch\",\n",
    "    bf16=False,  # Set to True if your GPU supports it\n",
    "    save_total_limit=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll set up the SFT trainer from TRL library and start training. This cell may take a long time to execute depending on your hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the SFT trainer\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_length=1024,\n",
    "    dataset_text_field=\"text\",\n",
    ")\n",
    "\n",
    "# To actually run training, uncomment the next line\n",
    "# This may take a long time depending on your hardware\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training, we would save the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model (uncomment after training)\n",
    "# model.save_pretrained(output_dir)\n",
    "# tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Fine-tuned Model\n",
    "\n",
    "After fine-tuning, we can test how our model performs on new transactions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_transaction(description, amount, model, tokenizer):\n",
    "    # Generate random categories including a likely correct one\n",
    "    if \"COFFEE\" in description or \"STARBUCKS\" in description:\n",
    "        likely_category = \"Food & Dining\"\n",
    "    elif \"AMAZON\" in description:\n",
    "        likely_category = \"Shopping\"\n",
    "    elif \"UBER\" in description or \"LYFT\" in description:\n",
    "        likely_category = \"Transportation\"\n",
    "    else:\n",
    "        likely_category = random.choice(ALL_CATEGORIES)\n",
    "        \n",
    "    options = get_category_options(likely_category)\n",
    "    options_text = \"- \" + \"\\n- \".join(options)\n",
    "    \n",
    "    # Create the prompt\n",
    "    prompt = f\"{SYSTEM_PROMPT}\\n\\nUser: Categorize this transaction: Description: {description}, Amount: ${amount}\\n\\nPossible categories:\\n{options_text}\\n\\nAssistant:\"\n",
    "    \n",
    "    print(\"\\nTest prompt:\")\n",
    "    print(prompt)\n",
    "    \n",
    "    # Generate a response\n",
    "    try:\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "        outputs = model.generate(\n",
    "            inputs.input_ids,\n",
    "            max_new_tokens=200,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            do_sample=True,\n",
    "        )\n",
    "        response = tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:], skip_special_tokens=True)\n",
    "        \n",
    "        print(\"\\nModel response:\")\n",
    "        print(response)\n",
    "        \n",
    "        # Extract the answer\n",
    "        if \"<answer>\" in response and \"</answer>\" in response:\n",
    "            answer = response.split(\"<answer>\")[1].split(\"</answer>\")[0].strip()\n",
    "            print(f\"\\nSelected category: {answer}\")\n",
    "        else:\n",
    "            print(\"\\nCould not extract category from response.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating response: {e}\")\n",
    "        print(\"Note: If you haven't trained the model yet, you'll need to do that first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a few examples\n",
    "test_examples = [\n",
    "    {\"description\": \"CHIPOTLE MEXICAN GRILL\", \"amount\": 12.49},\n",
    "    {\"description\": \"TESLA SUPERCHARGER\", \"amount\": 18.75},\n",
    "    {\"description\": \"SPOTIFY PREMIUM\", \"amount\": 9.99}\n",
    "]\n",
    "\n",
    "# Uncomment to test after training\n",
    "# for example in test_examples:\n",
    "#     test_transaction(example[\"description\"], example[\"amount\"], model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Alternative Approach with unsloth/vllm (Optional)\n",
    "\n",
    "For faster fine-tuning with larger models, you can use the `unsloth` and `vllm` libraries. This section is optional and requires additional dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to install unsloth and vllm\n",
    "# !pip install unsloth vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for unsloth approach (requires GPU with sufficient memory)\n",
    "\"\"\"\n",
    "from unsloth import FastLanguageModel, is_bfloat16_supported\n",
    "import torch\n",
    "\n",
    "# Configuration\n",
    "max_seq_length = 512\n",
    "lora_rank = 16\n",
    "\n",
    "# Load model with unsloth\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Phi-4\",  # You can change this to your preferred model\n",
    "    max_seq_length = max_seq_length,\n",
    "    load_in_4bit = True,\n",
    "    fast_inference = True,\n",
    "    max_lora_rank = lora_rank,\n",
    "    gpu_memory_utilization = 0.7,\n",
    ")\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = lora_rank,\n",
    "    target_modules = [\"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    lora_alpha = lora_rank,\n",
    "    use_gradient_checkpointing = \"unsloth\",\n",
    "    random_state = 3407,\n",
    ")\n",
    "\n",
    "# Training with GRPOTrainer\n",
    "from trl import GRPOConfig, GRPOTrainer\n",
    "\n",
    "training_args = GRPOConfig(\n",
    "    use_vllm = True,\n",
    "    learning_rate = 5e-6,\n",
    "    adam_beta1 = 0.9,\n",
    "    adam_beta2 = 0.99,\n",
    "    weight_decay = 0.1,\n",
    "    warmup_ratio = 0.1,\n",
    "    lr_scheduler_type = \"cosine\",\n",
    "    optim = \"paged_adamw_8bit\",\n",
    "    logging_steps = 1,\n",
    "    bf16 = is_bfloat16_supported(),\n",
    "    fp16 = not is_bfloat16_supported(),\n",
    "    per_device_train_batch_size = 1,\n",
    "    gradient_accumulation_steps = 1,\n",
    "    num_generations = 6,\n",
    "    max_prompt_length = 256,\n",
    "    max_completion_length = 200,\n",
    "    max_steps = 100,\n",
    "    save_steps = 250,\n",
    "    max_grad_norm = 0.1,\n",
    "    report_to = \"none\",\n",
    "    output_dir = \"outputs\",\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated how to fine-tune a model for transaction categorization using a multiple-choice approach. The key improvements over traditional approaches include:\n",
    "\n",
    "1. Providing a limited set of category options for each transaction\n",
    "2. Using a structured format for model responses\n",
    "3. Guiding the model to provide reasoning before giving an answer\n",
    "\n",
    "These improvements make the fine-tuning more focused and effective for real-world transaction categorization scenarios."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}